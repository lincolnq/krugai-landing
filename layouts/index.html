{{ define "header"}}
    &nbsp;
{{ end }}

{{ define "main" }}
<div id="homepage">
    <div class="section bg-washed-purple near-black">

        <h1 class="tc mb4">8 Facts About AI</h1>

        <div id="factcard1" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">1</div>
                <h1>Hundreds of AI scientists, including a Nobel Prize winner, co-signed a statement warning about the risk of extinction from AI.</h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>The <a href="https://aistatement.com/">CAIS Statement on AI Risk</a> reads in its entirety:</p>
                <blockquote>
                    Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.
                </blockquote>
                <p>It was signed by 695 leaders in AI, including 300+ top AI scientists.</p>

            </div>
        </div>


        <div id="factcard2" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">2</div>
                <h1>30 countries signed the Bletchley Declaration: “there is potential for serious, even catastrophic harm.”
                </h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p><a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">The Bletchley Declaration</a>
                    was the result of a diplomatic AI summit in the UK in 2023. Here's a quote:</p>
                <blockquote>
                    There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these AI models.
                </blockquote>
                <p>The declaration was signed by 30 countries, including the US, UK, and France.
                </p>
            </div>
            </h1>
        </div>


        <div id="factcard3" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">3</div>
                <h1>CEOs of AI companies admit a substantial risk of catastrophe from their work.</h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Sam Altman, CEO of OpenAI, said <a href="https://futureoflife.org/ai/sam-altman-investing-in-ai-safety-research/">in 2015</a>:</p>
                <blockquote>
                    AI will probably most likely lead to the end of the world, but in the meantime, there’ll be great companies.
                </blockquote>

                <p>Dario Amodei, CEO of Anthropic, said <a href="https://x.com/liron/status/1710520914444718459">in 2023</a>:</p>
                <blockquote>
                    I’ve often said that my chance that something goes really quite catastrophically wrong on the scale of human civilization might be somewhere around 10-25%.

                </blockquote>
            </div>
        </div>


        <div id="factcard4" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">4</div>
                <h1>According to scientists, AI powerful enough to destroy society could be built as soon as 2027.</h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Fill me in</p>
            </div>
        </div>


        <div id="factcard5" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">5</div>
                <h1>We are not slowing down: AI companies are building superintelligence as fast as they can.
                </h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Fill me in</p>
            </div>
        </div>


        <div id="factcard6" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">6</div>
                <h1>Progress has been much faster than experts predicted.
                </h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Fill me in</p>
            </div>
        </div>


        <div id="factcard7" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">7</div>
                <h1>AI companies are behaving like tobacco companies.
                </h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Fill me in</p>
            </div>
        </div>

        <div id="factcard8" class="factcard">
            <div class="factcard-header">
                <div class="factcard-number">8</div>
                <h1>AI will be able to do cognitive tasks better than humans.
                </h1>
                <div class="caret-pseudo"></div>
            </div>
            <div class="factcard-content">
                <p>Fill me in</p>
            </div>
        </div>

    </div>

    <div class="section bg-silver near-black">
        <div class="video-container">
            <iframe src="https://www.youtube.com/embed/PM5lUnmYeYQ" frameborder="0" allowfullscreen></iframe>
        </div>
    </div>

<script>
    const factcard_headers = document.querySelectorAll('.factcard-header');
    factcard_headers.forEach(factcardheader => {
        factcardheader.addEventListener('click', () => {
            factcardheader.parentElement.classList.toggle('expanded');
        });
    });

    // update aria-expanded attribute when toggling
    const factcards = document.querySelectorAll('.factcard');
    factcards.forEach(factcard => {
        const observer = new MutationObserver((mutations) => {
            mutations.forEach((mutation) => {
                    if (mutation.attributeName === 'class') {
                        const isExpanded = factcard.classList.contains('expanded');
                        factcard.setAttribute('aria-expanded', isExpanded);
                    }
                });
            });
    });
</script>

{{ end }}

{{ define "footer" }}
    
{{ end }}